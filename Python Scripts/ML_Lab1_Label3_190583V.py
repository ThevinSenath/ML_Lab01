# -*- coding: utf-8 -*-
"""ML_Lab1_Label3_190583V.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HdnczzLKTwqSWF2DlRQA0ogLjH_7ZsZ0
"""

from google.colab import drive
drive.mount('/content/drive')

"""Import required Libraries and Models."""

#import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.metrics import accuracy_score, precision_score, recall_score

"""Define constants."""

#define constants
LABELS = ['label_1', 'label_2', 'label_3', 'label_4']
FEATURES = ['feature_' + str(i) for i in range(1, 257)]
target_label = 'label_3'

"""Import train, valid and test datasets."""

#file paths for the datasets
train_path = '/content/drive/MyDrive/Colab Notebooks/Machine Learning/Lab1/train.csv'
valid_path = '/content/drive/MyDrive/Colab Notebooks/Machine Learning/Lab1/valid.csv'
test_path = '/content/drive/MyDrive/Colab Notebooks/Machine Learning/Lab1/test.csv'

#load the train dataset
train_data_set_original = pd.read_csv(train_path)

#load the valid dataset
valid_data_set_original = pd.read_csv(valid_path)

#load the test dataset
test_data_set_original = pd.read_csv(test_path)

"""Get the copies of train, valid and test datasets."""

#get a copy of the train dataset
train_data_set = train_data_set_original.copy()

#get a copy of the valid dataset
valid_data_set = valid_data_set_original.copy()

#get a copy of the test dataset
test_data_set = test_data_set_original.copy()

"""Visualize train, valid and test datasets.


"""

train_data_set.head()

valid_data_set.head()

test_data_set.head()

"""Drop the columns of the labels that contains null values."""

#get the columns contain null values
train_null_columns = train_data_set.columns[train_data_set.isnull().sum() > 0]

#drop rows with null values in the labels for training dataset
if (target_label in train_null_columns):
  train_data_set = train_data_set.dropna(subset=[target_label], how='any')

"""Fill the null values in the features with their means in the train, valid and test datasets."""

#fill null values with the mean in train data set.
train_data_set = train_data_set.fillna(train_data_set.mean())

#fill null values with the mean in valid data set.
valid_data_set = valid_data_set.fillna(valid_data_set.mean())

#fill null values with the mean in test data set.
test_data_set = test_data_set.fillna(test_data_set.mean())

"""Separate features and labels in the train, valid and test datasets."""

#seperate features and labels in train dataset.
train_features = train_data_set[FEATURES]
train_target_label = train_data_set[target_label]

#seperate features and labels in valid dataset.
valid_features = valid_data_set[FEATURES]
valid_target_label = valid_data_set[target_label]

#seperate features and labels in test dataset.
test_features = test_data_set[FEATURES]
test_target_label = test_data_set[target_label]

"""# 1. Predicting Label 3 without Feature Engineering

Standarize the features in the train, valid and test datasets.
"""

scaler = StandardScaler()

#standardize the features in train dataset
train_features = scaler.fit_transform(train_features)

#standardize the features in valid dataset
valid_features = scaler.transform(valid_features)

#standardize the features in test dataset
test_features = scaler.transform(test_features)

"""Train a model on the train dataset. Two classifires have been used and compared.

1. Support Vector Classifier(SVC)
2. Random Forest Classifier
3. K-Nearest Neighbors(KNN)


"""

#define a list of classification models
classification_models = [
    ('K Neighbors', KNeighborsClassifier()),
    ('Random Forest', RandomForestClassifier()),
    ('SVM', SVC(kernel='linear'))
]

for model_name, model in classification_models:

  model.fit(train_features, train_target_label)

  #predict on the train data
  y_pred_train = model.predict(train_features)

  #calculate metrics for classification evaluation on train data
  accuracy = accuracy_score(train_target_label, y_pred_train)
  precision = precision_score(train_target_label, y_pred_train, average='weighted', zero_division=1)
  recall = recall_score(train_target_label, y_pred_train, average='weighted')

  print(f"Metrics for {model_name} on train data:")
  print(f"Accuracy: {accuracy}")
  print(f"Precision: {precision}")
  print(f"Recall: {recall}")
  print("\n")

  #predict on the validation data
  y_pred_valid = model.predict(valid_features)

  #calculate metrics for classification evaluation on valid data
  accuracy = accuracy_score(valid_target_label, y_pred_valid)
  precision = precision_score(valid_target_label, y_pred_valid, average='weighted', zero_division=1)
  recall = recall_score(valid_target_label, y_pred_valid, average='weighted')

  print(f"Metrics for {model_name} on valid data:")
  print(f"Accuracy: {accuracy}")
  print(f"Precision: {precision}")
  print(f"Recall: {recall}")
  print("\n")

"""Predict on the test data using the best model."""

#predict on the test data
best_model = SVC(kernel='linear')
best_model.fit(train_features, train_target_label)
y_pred_test_before = best_model.predict(test_features)

"""# 2. Predicting Label 3 with Feature Engineering

Use feature selection based on correlation matrix and feature extraction based on PCA(Principal Component Analysis).

### Feature Selection

Visualize the distribution of the target label in train dataset.
"""

#plotting the distribution of target label in train dataset
labels, counts = np.unique(train_target_label, return_counts=True)
plt.figure(figsize=(12, 6))
plt.bar(labels, counts)
plt.xlabel('Target Label')
plt.ylabel('Frequency')
plt.title('Distribution of the Target Label')
plt.show()

"""Calculate the correlation matrix of the features in the train dataset."""

#calculate the correlation matrix
corr_matrix = pd.DataFrame(train_features).corr()

#set the threshold for correlation
corr_threshold = 0.9

#get the filtered correlation matrix and plot it
filtered_corr_matrix = corr_matrix[(corr_matrix > corr_threshold) | (corr_matrix < -corr_threshold)]
plt.figure(figsize=(10, 8))
sns.heatmap(filtered_corr_matrix, cmap='coolwarm', center=0, annot=True)
plt.title("Correlation Matrix")
plt.show()

"""Identify the features that are most correlated with each other using the traning dataset. Threshold of 0.9 has been used to find the most correlated features."""

most_correlated_features = set()

#get most correlated features
for i in range(len(corr_matrix.columns)):
    for j in range(i):
        if abs(corr_matrix.iloc[i, j]) > corr_threshold:
            col_name = corr_matrix.columns[i]
            most_correlated_features.add(col_name)

"""Remove the most correlated features from all the datasets."""

#remove most correlated features
train_features = pd.DataFrame(train_features).drop(columns=most_correlated_features)
valid_features = pd.DataFrame(valid_features).drop(columns=most_correlated_features)
test_features = pd.DataFrame(test_features).drop(columns=most_correlated_features)

"""Print the new shapes of all the datasets after removing the most correlated features."""

#print the new feature count in train dataset
print("New Features in Train Dataset: {}".format(train_features.shape))

#print the new feature count in valid dataset
print("New Features in Valid Dataset: {}".format(valid_features.shape))

#print the new feature count in test dataset
print("New Features in Test Dataset: {}".format(test_features.shape))

"""Identify the features that are most correlated with the target label using the traning dataset. Threshold of 0.05 has been used to find the most correlated features."""

#calculate the correlation matrix between features and target label in train dataset
corr_with_target = pd.DataFrame(train_features).corrwith(train_target_label)

#set the correlation threshold
corr_threshold = 0.05

#select features that meet the correlation threshold
most_correlated_features_with_target = corr_with_target[corr_with_target.abs() > corr_threshold]

"""Extract the  most correlated features with the target label from all datasets."""

#extract the  most correlated features with the target label in train dataset
train_features = train_features[most_correlated_features_with_target.index]

#extract the  most correlated features with the target label in valid dataset
valid_features = valid_features[most_correlated_features_with_target.index]

#extract the  most correlated features with the target label in test dataset
test_features = test_features[most_correlated_features_with_target.index]

"""Print the new shapes of all the datasets after extracting the most correlated features."""

#print the new feature count in train dataset
print("New Features in Train Dataset: {}".format(train_features.shape))

#print the new feature count in valid dataset
print("New Features in Valid Dataset: {}".format(valid_features.shape))

#print the new feature count in test dataset
print("New Features in Test Dataset: {}".format(test_features.shape))

"""Standarize the features in the train, valid and test datasets."""

scaler = StandardScaler()

#standardize the features in train dataset
standardized_train_features = scaler.fit_transform(train_features)

#standardize the features in valid dataset
standardized_valid_features = scaler.transform(valid_features)

#standardize the features in test dataset
standardized_test_features = scaler.transform(test_features)

"""### Feature Extraction

Extract can combine the features that are highly significant in predicting the label using PCA.

Extract the features that can explain the variance of the label to 99%

Display the resulting explained variances of each principal component
"""

variance_threshold = 0.99

#apply PCA with the determined number of components
pca = PCA(n_components=variance_threshold, svd_solver='full')

pca_train = pca.fit_transform(standardized_train_features)
pca_valid = pca.transform(standardized_valid_features)
pca_test = pca.transform(standardized_test_features)

#explained variance ratio after dimensionality reduction
explained_variance_ratio_reduced = pca.explained_variance_ratio_

#print the new feature count in train dataset
print("New Features in Train Dataset: {}".format(pca_train.shape))
#print the new feature count in valid dataset
print("New Features in Valid Dataset: {}".format(pca_valid.shape))
#print the new feature count in test dataset
print("New Features in Test Dataset: {}".format(pca_test.shape))

"""Used the trained model using the extracted features and preddict and get the evaluation metrics. Here also SVC and KNN classifiers have been used and compared."""

#define a list of classification models
classification_models = [
    ('K Neighbors', KNeighborsClassifier()),
    ('Random Forest', RandomForestClassifier()),
    ('SVM', SVC())
]

#number of features used in PCA
num_of_features = pca_train.shape[1]
print(f"Number of features: {num_of_features}\n")

for model_name, model in classification_models:

  model.fit(pca_train, train_target_label)

  #predict on the train data
  y_pred_train = model.predict(pca_train)

  #calculate metrics for classification evaluation on train data
  accuracy = accuracy_score(train_target_label, y_pred_train)
  precision = precision_score(train_target_label, y_pred_train, average='weighted', zero_division=1)
  recall = recall_score(train_target_label, y_pred_train, average='weighted')

  print(f"Metrics for {model_name} on train data:")
  print(f"Accuracy: {accuracy}")
  print(f"Precision: {precision}")
  print(f"Recall: {recall}")
  print("\n")

  #predict on the validation data
  y_pred_valid = model.predict(pca_valid)

  #calculate metrics for classification evaluation on validation data
  accuracy = accuracy_score(valid_target_label, y_pred_valid)
  precision = precision_score(valid_target_label, y_pred_valid, average='weighted', zero_division=1)
  recall = recall_score(valid_target_label, y_pred_valid, average='weighted')

  print(f"Metrics for {model_name} on validation data:")
  print(f"Accuracy: {accuracy}")
  print(f"Precision: {precision}")
  print(f"Recall: {recall}")
  print("\n")

"""Predict on the test data using the best model.

According to the results SVC is classifier gives better predictions.Therefore predictions on the test data is done by using SVC classifier.
"""

#predict on the test data
best_model = SVC(kernel='linear')
best_model.fit(pca_train, train_target_label)
y_pred_test_after = best_model.predict(pca_test)

"""#Create the CSV file.

Define method to create the csv file.
"""

# define method to create the dataframe and save it as a csv file
def create_csv(features, pred_before_fe, pred_after_fe, destination):
  feature_count = features.shape[1]

  header_row = [f"new_feature_{i}" for i in range(1,feature_count+1)]

  df = pd.DataFrame(features, columns  = header_row)

  df.insert(loc=0, column='Predicted labels before feature engineering', value=pred_before_fe)
  df.insert(loc=1, column='Predicted labels after feature engineering', value=pred_after_fe)
  df.insert(loc=2, column='No of new features', value=np.repeat(feature_count, features.shape[0]))

  df.to_csv(destination, index=False)

"""Save the csv file."""

destination = '/content/drive/MyDrive/Colab Notebooks/Machine Learning/Lab1/190583V_label3.csv'

# create the csv output file
create_csv(pca_test, y_pred_test_before, y_pred_test_after, destination)